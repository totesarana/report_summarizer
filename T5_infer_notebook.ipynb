{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This file is to quickly review the trained summarize model output.\n",
    "##### Debug and Development purpose only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import datasets as hf_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the model to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = './t5-base-finetuned-20230907/checkpoint-46500'\n",
    "summarizer = pipeline(\"summarization\", tokenizer=checkpoint, framework='pt', model=checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose dataset to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AILab_env\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\z003t1zx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from T5_only_summarize_demo_train import read_in_dataset\n",
    "mydataset = read_in_dataset()\n",
    "mydataset['summary'] = [k['0'] for k in mydataset['summary']]\n",
    "mydataset = hf_datasets.Dataset.from_dict(mydataset)\n",
    "train_test = mydataset.train_test_split(test_size=0.2, seed=66)\n",
    "train_val = train_test['train'].train_test_split(test_size=0.2, seed=88)\n",
    "#Need to do test on testing data\n",
    "testing_data = train_test['test']\n",
    "del train_test, train_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on one single random data from testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Finetune: \n",
      "##############################\n",
      "Your CT scan showed some thickening in the right lung, fluid, and a mass or hematoma in the right spinal area. The ascending aorta is mildly enlarged, and there are calcified lymph nodes in the hila. Further evaluation with a bone scan, PET/CT, and MRI is recommended.\n",
      "Ground Truth: \n",
      "##############################\n",
      "The CT scan shows some pleural thickening and reticular lines in the right chest base, with mild fibrosis. There is also pleural thickening, fluid, and possible atelectasis. The left base has similar findings but to a lesser extent. No worrisome nodules or masses were observed. There is a lytic destructive process in the 10th vertebral body, and further evaluation is recommended. \n",
      "##############################\n",
      "original_text\n",
      "\\n**REMOVED,_P.C.\\n**HEADERFIELD\\n**HEADERFIELD\\n**HEADERFIELD\\nExamination Report\\nTo:**HEADERFIELD\\n**HEADERFIELD\\n**HEADERFIELD\\n**HEADERFIELD\\nFax#:    \\nExam#: 404679 - 71250 71250 CT CHEST W/O\\nCT SCAN of THE CHEST WITHOUT CONTRAST\\nINDICATION:  Followup previous study from **DATE. The chest x-ray showing increased\\nmarkings.\\nTECHNIQUE:  Volumetric data set is acquired through the chest without IV or oral contrast.\\nFINDINGS:\\nThere is pleural thickening noted on the right with subpleural Reticular lines in the right base as well as\\nsome pleural thickening, pleural fluid, and basilar probable atelectasis. There is less extensive Reticular\\nfindings in the left base and minimal patchy ground glass opacity bilaterally in the bases. There is some\\nthickening noted within the minor fissure, which could be tracking pleural fluid or pleural thickening.\\nThere is no worrisome nodule or Parenchymal mass seen.\\nThe ascending aorta is 4.2 cm likely mildly enlarged. There are calcified lymph nodes in the hila\\nbilaterally up to 13 mm in the right pretracheal region inferiorly. There is Coronary artery calcification.\\nThere is multiple Areas of lysis within T10 vertebral body which is also minimally sclerotic. There is\\nparaspinal widening on the right at T10 and T11 suggesting a soft tissue mass or hematoma.  The\\nremaining vertebral bodies appear otherwise without focal lytic or destructive process. There is\\nextensive degenerative disc disease and scoliosis as well noted. The upper abdomen is unremarkable,\\nthe gallbladder is somewhat conTracted and suboptimally evaluated.\\nIMPRESSION:\\nRight greater than left basilar fibrosis of mild to moderate degree associated with right pleural thickening\\nand pleural fluid and right paraspinal mass versus hematoma and lytic destructive process in the 10th\\nvertebral body. Suggest bone scan correlation for whole body survey versus PET/CT and MRI\\ncorrelation without and with Gadolinium of the thoracic spine for further local  evaluation.  \\nElectronically_Signed:**HEADERFIELD\\n\\n**REMOVED,_P.C.\\n**HEADERFIELD\\n**HEADERFIELD\\n**HEADERFIELD\\nExamination Report\\nTo:**HEADERFIELD\\n**HEADERFIELD\\n**HEADERFIELD\\n**HEADERFIELD\\nFax#:    \\nExam#: 404679 - 71250 71250 CT CHEST W/O\\nElectronically_Signed_by**HEADERFIELD\\n\\n\\n\\n--Anonymized using SiemensBDO Report Anonymizer v4.0\n"
     ]
    }
   ],
   "source": [
    "sample = testing_data.select(range(1117,1118))\n",
    "suid = sample['suid'][0]\n",
    "paragraph = 'summarize: ' + sample['text'][0]\n",
    "gt = sample['summary'][0]\n",
    "predicted = summarizer(paragraph)\n",
    "\n",
    "print('Predicted Finetune: ')\n",
    "print(\"##############################\")\n",
    "print(predicted[0]['summary_text'])\n",
    "print('Ground Truth: ')\n",
    "print(\"##############################\")\n",
    "print(gt)\n",
    "print(\"##############################\")\n",
    "print('original_text')\n",
    "print(sample['text'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Baseline: \n",
      "***************************\n",
      "chest x-ray shows increasednmarkings . no worrisome nodule or Parenchymal mass seen . pleural thickening noted on the right with subpleural lines .\n",
      "***************************\n",
      "The CT scan shows some pleural thickening and reticular lines in the right chest base, with mild fibrosis. There is also pleural thickening, fluid, and possible atelectasis. The left base has similar findings but to a lesser extent. No worrisome nodules or masses were observed. There is a lytic destructive process in the 10th vertebral body, and further evaluation is recommended. \n"
     ]
    }
   ],
   "source": [
    "checkpoint_baseline = 't5-base'\n",
    "summarizer_base = pipeline(\"summarization\", tokenizer=checkpoint_baseline, framework='pt', model=checkpoint_baseline)\n",
    "predicted_base = summarizer_base(paragraph)\n",
    "print('Predicted Baseline: ')\n",
    "print(\"***************************\")\n",
    "print(predicted_base[0]['summary_text'])\n",
    "print(\"***************************\")\n",
    "print(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 not using pipeline (multi-task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import prepare\n",
    "import json\n",
    "jsonfile = \"F:/SmartReport/GT.json\"\n",
    "trimmed_dataset = prepare.read_in_dataset(jsonfile=jsonfile)\n",
    "with open(\"F:/SmartReport/split_2023-09-19_11-44-08.json\") as fid:\n",
    "    train_val_test_split = json.load(fid)\n",
    "test_suids = set(train_val_test_split['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build test data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "testing_dict = defaultdict(defaultdict)\n",
    "for idx in range(len(trimmed_dataset['suid'])):\n",
    "    suid = trimmed_dataset['suid'][idx]\n",
    "    if suid in test_suids:\n",
    "        testing_dict[suid]['context'] = trimmed_dataset['text'][idx]\n",
    "        testing_dict[suid]['summary'] = trimmed_dataset['summary'][idx]\n",
    "        testing_dict[suid]['malignancy'] = trimmed_dataset['malignancy'][idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end2end prediction multi task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration  \n",
    "  \n",
    "# Initialize the tokenizer and model  \n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base', model_max_length=1024, padding='max_length')  \n",
    "model = T5ForConditionalGeneration.from_pretrained('F:/SmartReport/Training_snapshots/t5-base-finetuned/checkpoint-3000')  \n",
    "  \n",
    "# Define the text  \n",
    "selected_suid = list(testing_dict.keys())[0]\n",
    "text = 'summarize: ' + testing_dict[selected_suid]['context']\n",
    "#text = 'question: is there cancer or malignant nodule? ' +'context: '+ testing_dict[selected_suid]['context']\n",
    "  \n",
    "# Tokenize the text  \n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')  \n",
    "  \n",
    "# Generate output  \n",
    "output = model.generate(input_ids, max_length=200)  \n",
    "  \n",
    "# Decode the output  \n",
    "decoded_output = tokenizer.decode(output[0])  \n",
    "  \n",
    "print(decoded_output)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AILab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
